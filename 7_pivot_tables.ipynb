{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivot tables with Pandas\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "At the end of this notebook you should be able to\n",
    "- create pivot tables with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing modules and loading the Datasets.  \n",
    "\n",
    "Note: please use the __nf_geo environment__ again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard import of pandas\n",
    "import pandas as pd\n",
    "\n",
    "# additional import of the geopandas package\n",
    "import geopandas as gpd\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# hides warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you don't need to look too close at this cell - it just recreates the datatsets as already known before!\n",
    "\n",
    "# bike theft data\n",
    "thefts_df = pd.read_csv('data/Fahrraddiebstahl.csv', encoding='latin-1') # proper encoding is necessary here!\n",
    "thefts_df.columns = thefts_df.columns.str.lower()  # make column names lowercase\n",
    "\n",
    "# geodataframe based on the shapefile\n",
    "gdf = gpd.GeoDataFrame.from_file('data/LOR_SHP_2021/lor_plr.shp')\n",
    "gdf.columns = gdf.columns.str.lower()\n",
    "\n",
    "# recreate the bike theft raw dataframe as in the notebook before.\n",
    "thefts_df['lor_str'] = thefts_df['lor'].astype('str') # changing the lor column datatype to string\n",
    "thefts_df['plr_id'] = thefts_df['lor_str'].apply(lambda x: x.zfill(8)) # fill leading gaps up to 8 characters with zeros and call the new column accordingly to the geodataframe\n",
    "thefts_df.drop(columns=['lor', 'lor_str'], inplace=True) # dropping no longer needed columns\n",
    "gdf_biketheft = gdf.merge(thefts_df, on='plr_id') # merging\n",
    "\n",
    "# red wine dataset\n",
    "red_wines_df = pd.read_csv('data/winequality-red.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b691867a",
   "metadata": {},
   "source": [
    "## Pivot tables\n",
    "\n",
    "From [wiki](https://en.wikipedia.org/wiki/Pivot_table): \"Among other functions, a pivot table can automatically sort, count total, or give the average of the data stored in one table or spreadsheet, displaying the results in a second table showing the summarized data. Pivot tables are also useful for quickly creating unweighted cross tabulations.\"\n",
    "\n",
    "As you might have guessed, we have functionality to create pivot tables available for our use in Pandas. The way that we do this is by calling the `pivot_table()` function that is available on the pandas module (which we've stored as `pd`). As the [docs](https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html) tell us, the `pivot_table()` expects a number of different arguments: \n",
    "\n",
    "1. `data`: A DataFrame object\n",
    "2. `values`: a column or a list of columns to aggregate\n",
    "3. `index`: a column, Grouper, array which has the same length as data, or list of them. Keys to group by on the pivot table index. If an array is passed, it is being used as the same manner as column values.\n",
    "4. `columns`: a column, Grouper, array which has the same length as data, or list of them. Keys to group by on the pivot table column. If an array is passed, it is being used as the same manner as column values.\n",
    "5. `aggfunc`: function to use for aggregation, defaulting to numpy.mean\n",
    "\n",
    "Notice that by default this uses the mean for the `aggfunc` parameter. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc202ebb",
   "metadata": {},
   "source": [
    "1. For this example, we want to show the max theft value for each type of bike and each district.  \n",
    "Let's have a look at the available columns again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6de95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_biketheft.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad078c8",
   "metadata": {},
   "source": [
    "We choose for the name of the district as the rows and the type of bike as columns to aggregate on,  \n",
    "and the aggregation in this case is the maximum value.  \n",
    "Also we fill the NaNs with zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b531fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can specify a function to aggregate with (by default it is mean)\n",
    "pd.pivot_table(gdf_biketheft,\n",
    "                values='schadenshoehe',\n",
    "                index='plr_name',\n",
    "                columns='art_des_fahrrads',\n",
    "                aggfunc=max,\n",
    "                fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check your understanding\n",
    "\n",
    "2. For the second pivot table, we ask you to recreate a similar table as the final table of the previous notebook showing the _theft count_ and the _mean theft amount_ as shown in the example below.  \n",
    "You can choose for the columns to display and the functions to aggregate by,  \n",
    "the syntax is in the comment in the cell below.  \n",
    "\n",
    "Try to make it look like this:  \n",
    "<!-- ![pivot_table](images/biketheft_pivot.png) -->\n",
    "<img src=\"images/biketheft_pivot.png\" alt=\"drawing\" width=\"40% of window\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please ignore the slightly different values to the previous notebook - since we spared ourselves the cleaning.\n",
    "\"\\N{smiling face with sunglasses}\" * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic syntax of a pivot table with aggregate function \"aggfunc\" dictionary:\n",
    "''' table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
    "                     aggfunc={'D': np.mean,\n",
    "                              'E': np.mean})'''\n",
    "                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b691867a",
   "metadata": {},
   "source": [
    "## Pivot tables and binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c437ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point, we deserve some good wine again!\n",
    "# Let's recall what the data looks like. \n",
    "red_wines_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5931a455",
   "metadata": {},
   "source": [
    "Let's take a moment to quickly learn about another Pandas function called `cut()` that allows us to turn a column with continuous data into categories by specifying bins to place them in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be65740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create categories, bins should start with number 4 and end with 17. Since no step size is given, 1 is taken as default.\n",
    "# Numpy functionalities are covered in more depth in the next notebook\n",
    "import numpy as np\n",
    "pd.cut(red_wines_df['fixed acidity'], bins=np.arange(4, 17)).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fb9832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a new column with fixed_acidity split into categories\n",
    "# 1. Create bins using np.arrange\n",
    "fixed_acidity_bins = np.arange(4, 17)\n",
    "\n",
    "# 2. Create categories for fixed acidity, using the bins created above. \n",
    "# The labels of the categories are the lower boundary of the bins\n",
    "\n",
    "fixed_acidity_series = pd.cut(red_wines_df['fixed acidity'], bins=fixed_acidity_bins, \n",
    "                              labels=fixed_acidity_bins[:-1])\n",
    "\n",
    "# Give series a name, which will be the new column's name\n",
    "fixed_acidity_series.name = 'fa_bin'\n",
    "\n",
    "# Concatenate the original df with the newly created series\n",
    "red_wines_df = pd.concat([red_wines_df, fixed_acidity_series], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6ded83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the resulting df\n",
    "red_wines_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7890b5",
   "metadata": {},
   "source": [
    "Now we can get the mean residual sugar for each quality category/fixed acidity bin like we did earlier, but with a pivot_table (mean is the default aggregation function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705598d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(red_wines_df,\n",
    "            values='residual sugar', \n",
    "            index='quality', \n",
    "            columns='fa_bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee258958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or, we specify \"max\" as a function to aggregate with\n",
    "pd.pivot_table(red_wines_df,\n",
    "             values='residual sugar', \n",
    "             index='quality', \n",
    "             columns='fa_bin',\n",
    "             aggfunc=np.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "pop the corks!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ab6d479e1cd2ec09bf4553ae31932a1423a05209177038e7b1d0f242d7ebca8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('nf_base_new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
